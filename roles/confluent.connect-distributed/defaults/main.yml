kafka:
  connect:
    distributed:
      config_dir: "{{confluent_config_dir}}"
      config_file: "connect-distributed.properties"
      data_dir: "{{ data_base_dir }}/connect"
      service_name: confluent-kafka-connect
      user: connect
      group: rioapp
      environment:
        KAFKA_HEAP_OPTS: "-Xms256M -Xmx2G"
      config:
        rest.port: 8083
        consumer.interceptor.classes: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
        producer.interceptor.classes: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
        ssl.endpoint.identification.algorithm: ""
        consumer.ssl.endpoint.identification.algorithm: ""
        producer.ssl.endpoint.identification.algorithm: ""
        config.storage.replication.factor: 3
        config.storage.topic: connect-configs
        group.id: connect-cluster
        internal.key.converter: org.apache.kafka.connect.json.JsonConverter
        internal.key.converter.schemas.enable: false
        internal.value.converter: org.apache.kafka.connect.json.JsonConverter
        internal.value.converter.schemas.enable: false
        offset.flush.interval.ms: 10000
        offset.storage.replication.factor: 3
        offset.storage.topic: connect-offsets
        status.storage.replication.factor: 3
        status.storage.topic: connect-status
        key.converter: io.confluent.connect.avro.AvroConverter
        value.converter: io.confluent.connect.avro.AvroConverter
        plugin.path: "{{ confluent_home }}/java/"
        listeners: "https://0.0.0.0:8083"
      systemd:
        enabled: yes
        state: started

